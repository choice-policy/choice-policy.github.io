<!doctype html>
<html lang="en">

<head>
  <!-- Meta tags -->
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <!-- HTML Meta Tags -->
  <title>Coordinated Humanoid Manipulation with Choice Policies</title>
  <meta name="description" content="Coordinated Humanoid Manipulation with Choice Policies" />
  <meta property="og:image" content="./imgs/teaser.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="Coordinated Humanoid Manipulation with Choice Policies" />
  <meta property="og:description" content="We present a teleoperation system and a policy learning framework for coordinated humanoid manipulation." />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous" />

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;0,900&family=Varela+Round&display=swap" rel="stylesheet">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¦¾</text></svg>" />
  <!-- Bootstrap JS -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
    crossorigin="anonymous"></script>
  <!-- Customized style -->
  <style>
    html * {
      color: #333;
      font-family: "Lato", sans-serif;
    }

    body {
      background-color: #ffffff;
    }

    table.results td {
      color: #888;
      font-size: 90%;
    }

    .mtitle {
      margin-top: 0;
      font-family: "Varela Round", sans-serif;
      color: #000000;
      font-size: 40px;
      line-height: 60px;
      font-weight: 600;
      letter-spacing: 1px;
    }

    .msubtitle {
      margin-top: -30px;
      margin-bottom: -20px;
      font-size: 23px;
      line-height: 65px;
      letter-spacing: 2px;
    }

    .mauthors {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      font-size: 16px;
      font-weight: 400;
      gap: 0.6rem;
    }

    .mauthors a {
      text-decoration: none;
    }

    .mauthors a:hover {
      text-decoration: none;
    }

    .mauthors_affiliation {
      margin-bottom: 24px;
      font-size: 16px;
    }

    .darker_bg {
      padding-top: 32px;
      padding-bottom: 32px;
      background-color: #f5f5f5;
    }

    .nav-link {
      color: #333;
    }

    .nav-link a:hover,
    a:hover,
    a:active {
      color: #888 !important;
    }

    .video-container {
      position: relative;
      width: 100%;
      border-radius: 1rem;
      overflow: hidden;
      box-shadow: 0 8px 24px rgba(0, 0, 0, 0.15);
      margin-bottom: 0.5rem;
    }

    .video-container video {
      width: 100%;
      display: block;
    }

    .my-5 h3 {
      text-align: center;
    }

    /* === Slider core === */
    .slider-wrapper {
      position: relative;
      width: 100%;
      max-width: 850px;
      margin: 2rem auto;
    }

    .slider-container {
      width: 100%;
      aspect-ratio: 16 / 9;
      background: #000;
      overflow: hidden;
      border-radius: 1rem;
      box-shadow: 0 8px 24px rgba(0, 0, 0, 0.15);
    }

    .slider-track {
      display: flex;
      width: 100%;
      height: 99.5%;
      transition: transform 0.45s ease-in-out;
    }

    .slide-video {
      flex: 0 0 100%;
      width: 100%;
      height: 100%;
      object-fit: contain;
      display: block;
    }

    .quick-links {
      text-align: center;
      margin-top: -10px;
      margin-bottom: 25px;
    }

    .quick-links a {
      margin: 0 2.5rem;
      text-decoration: underline;
    }

    .nav-arrow {
      position: absolute;
      top: 50%;
      transform: translateY(-50%);
      font-size: 2rem;
      padding: 0.5rem 0.9rem;
      line-height: 1;
      border-radius: 999px;
      background: #333;
      color: white;
      border: none;
      cursor: pointer;
      transition: background 0.3s ease, box-shadow 0.3s ease;
      z-index: 2;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.25);
    }

    .nav-arrow-left {
      left: -40px;
    }

    .nav-arrow-right {
      right: -40px;
    }

    @media (max-width: 768px) {
      .nav-arrow-left {
        left: -20px;
      }

      .nav-arrow-right {
        right: -20px;
      }
    }

    .nav-arrow:hover {
      background: #555;
    }

    .slider-indicators {
      display: flex;
      justify-content: center;
      gap: 0.6rem;
      margin-top: 0.75rem;
    }

    .slider-dot {
      width: 10px;
      height: 10px;
      border-radius: 999px;
      border: none;
      background: #ccc;
      padding: 0;
      cursor: pointer;
      transition: background 0.25s ease, transform 0.25s ease;
    }

    .slider-dot.active {
      background: #333;
      transform: scale(1.2);
    }

    .abstract-section p {
      line-height: 1.8;
      text-align: justify;
    }
  </style>
</head>

<body>
  <div class="container-fluid my-5 mx-auto" style="max-width: 1000px">
    <div class="row">
      <h1 class="display-12 text-center mtitle">
        Coordinated Humanoid Manipulation with Choice Policies
      </h1>
    </div>

    <div class="text-center mauthors" style="line-height: 1.6; margin-top: 1rem;">
      <span class="author-block"><a href="https://haozhi.io/">Haozhi Qi</a><sup>*</sup></span>
      <span class="author-block"><a href="https://wangyenjen.github.io/">Yen-Jen Wang</a><sup>*</sup>,</span>
      <span class="author-block"><a href="https://toruowo.github.io/">Toru Lin</a>,</span>
      <span class="author-block"><a href="https://brentyi.github.io/">Brent Yi</a>,</span>
      <span class="author-block"><a href="https://people.eecs.berkeley.edu/~yima/">Yi Ma</a>,</span>
      <span class="author-block"><a href="https://me.berkeley.edu/people/koushil-sreenath/">Koushil Sreenath</a><sup>â€ </sup>,</span>
      <span class="author-block"><a href="https://people.eecs.berkeley.edu/~malik/">Jitendra Malik</a><sup>â€ </sup></span>
    </div>

    <!-- Footnotes -->
    <div class="text-center my-2" style="font-size: 0.85rem; color: #888;">
      <sup>*</sup> Equal contribution. <sup>â€ </sup> Equal advising.
    </div>

    <!-- Affiliation -->
    <div class="text-center mauthors_affiliation">
      UC Berkeley
    </div>

    <div class="quick-links">
      <a href="https://arxiv.org/abs/2512.25072" target="_blank">
        <svg style="width: 16px; height: 16px; vertical-align: middle; margin-right: 4px;" viewBox="0 0 24 24">
          <path fill="currentColor"
            d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z" />
        </svg>
        Paper
      </a>
      <a href="https://github.com/x-robotics-lab/modular-teleop">
        <svg style="width: 16px; height: 16px; vertical-align: middle; margin-right: 4px;" viewBox="0 0 24 24">
          <path fill="currentColor"
            d="M12,2A10,10 0 0,0 2,12C2,16.42 4.87,20.17 8.84,21.5C9.34,21.58 9.5,21.27 9.5,21C9.5,20.77 9.5,20.14 9.5,19.31C6.73,19.91 6.14,17.97 6.14,17.97C5.68,16.81 5.03,16.5 5.03,16.5C4.12,15.88 5.1,15.9 5.1,15.9C6.1,15.97 6.63,16.93 6.63,16.93C7.5,18.45 8.97,18 9.54,17.76C9.63,17.11 9.89,16.67 10.17,16.42C7.95,16.17 5.62,15.31 5.62,11.5C5.62,10.39 6,9.5 6.65,8.79C6.55,8.54 6.2,7.5 6.75,6.15C6.75,6.15 7.59,5.88 9.5,7.17C10.29,6.95 11.15,6.84 12,6.84C12.85,6.84 13.71,6.95 14.5,7.17C16.41,5.88 17.25,6.15 17.25,6.15C17.8,7.5 17.45,8.54 17.35,8.79C18,9.5 18.38,10.39 18.38,11.5C18.38,15.32 16.04,16.16 13.81,16.41C14.17,16.72 14.5,17.33 14.5,18.26C14.5,19.6 14.5,20.68 14.5,21C14.5,21.27 14.66,21.59 15.17,21.5C19.14,20.16 22,16.42 22,12A10,10 0 0,0 12,2Z" />
        </svg>
        Code (Teleop)
      </a>
      <a href="https://github.com/x-robotics-lab/minbc">
        <svg style="width: 16px; height: 16px; vertical-align: middle; margin-right: 4px;" viewBox="0 0 24 24">
          <path fill="currentColor"
            d="M12,2A10,10 0 0,0 2,12C2,16.42 4.87,20.17 8.84,21.5C9.34,21.58 9.5,21.27 9.5,21C9.5,20.77 9.5,20.14 9.5,19.31C6.73,19.91 6.14,17.97 6.14,17.97C5.68,16.81 5.03,16.5 5.03,16.5C4.12,15.88 5.1,15.9 5.1,15.9C6.1,15.97 6.63,16.93 6.63,16.93C7.5,18.45 8.97,18 9.54,17.76C9.63,17.11 9.89,16.67 10.17,16.42C7.95,16.17 5.62,15.31 5.62,11.5C5.62,10.39 6,9.5 6.65,8.79C6.55,8.54 6.2,7.5 6.75,6.15C6.75,6.15 7.59,5.88 9.5,7.17C10.29,6.95 11.15,6.84 12,6.84C12.85,6.84 13.71,6.95 14.5,7.17C16.41,5.88 17.25,6.15 17.25,6.15C17.8,7.5 17.45,8.54 17.35,8.79C18,9.5 18.38,10.39 18.38,11.5C18.38,15.32 16.04,16.16 13.81,16.41C14.17,16.72 14.5,17.33 14.5,18.26C14.5,19.6 14.5,20.68 14.5,21C14.5,21.27 14.66,21.59 15.17,21.5C19.14,20.16 22,16.42 22,12A10,10 0 0,0 12,2Z" />
        </svg>
        Code (Policy)
      </a>
    </div>

    <div class="row">
      <h5 class="text-center">Abstract:</h5>
      <p style="font-size: 1.1rem; font-weight: 500; margin-top: 0px;">
        Humanoid robots hold great promise for operating in human-centric environments, yet achieving robust whole-body coordination across the head, hands, and legs remains a major challenge. We present a system that combines a modular teleoperation interface with a scalable learning framework to address this problem. Our teleoperation design decomposes humanoid control into intuitive submodules, which include hand-eye coordination, grasp primitives, arm end-effector tracking, and locomotion. This modularity allows us to collect high-quality demonstrations efficiently. Building on this, we introduce Choice Policy, an imitation learning approach that generates multiple candidate actions and learns to score them. This architecture enables both fast inference and effective modeling of multimodal behaviors. We validate our approach on two real-world tasks: dishwasher loading and whole-body loco-manipulation for whiteboard wiping. Experiments show that Choice Policy significantly outperforms diffusion policies and standard behavior cloning. Furthermore, our results indicate that hand-eye coordination is critical for success in long-horizon tasks. Our work demonstrates a practical path toward scalable data collection and learning for coordinated humanoid manipulation in unstructured environments.
      </p>
    </div>

    <div class="my-5">
      <h3 class="mt-4 mb-3">Highlight Results</h3>
      <div class="row mt-4">
        <div class="col-md-6">
          <h5 class="text-center mb-3">Dishwasher Loading</h5>
          <div class="video-container">
            <video autoplay muted loop playsinline controls preload="metadata">
              <source data-src="./videos/dishwasher.mp4">
            </video>
          </div>
        </div>

        <div class="col-md-6">
          <h5 class="text-center mb-3">Loco-manipulation Wiping</h5>
          <div class="video-container">
            <video autoplay muted loop playsinline controls preload="metadata">
              <source data-src="./videos/wiping.mp4">
            </video>
          </div>
        </div>
      </div>
      <p>Our framework enables the humanoid to perform diverse, long-horizon tasks. In Dishwasher Loading, the robot coordinates gaze and reach to handle object insertion. In Loco-manipulation Wiping, the system maintains balance and walking stability, showcasing the tight integration of locomotion and manipulation.</p>
    </div>

    <div class="my-5">
      <h3 class="mt-4 mb-3"> Teleoperation </h3>
      <img src="./images/teleop.png" alt="Teleoperation" style="width: 100%;">
      <p style="margin-top: 0.8rem; font-size: 1.0rem">
        Our modular teleoperation interface simplifies complex humanoid control by decomposing whole-body movements into intuitive functional submodules.
        By providing automated hand-eye coordination and high-level locomotion primitives via a VR interface,
        we enable operators to collect high-quality demonstrations for long-horizon tasks with minimal physical fatigue.
      </p>
    </div>

    <div class="my-5">
      <h3 class="mt-4 mb-3">Comparison of learning method</h3>
      <center>
        <img src="./images/learning.png" alt="Stage 3" style="width: 60%;">
      </center>
      <p style="margin-top: 0.8rem; font-size: 1.0rem">
        We introduce <b>Choice Policy</b>,
        a learning framework designed to handle the inherent multimodality of human expert data.
        Unlike diffusion models that require iterative sampling, our method generate multiple action candidates and score them in a single forward pass.
      </p>
    </div>

    <div class="my-5">
      <h4 class="text-center mt-4 mb-3">Evaluation (10 Consecutive Trials)</h4>
      <p class="text-left" style="margin-top: 0.8rem; font-size: 1.0rem">
        We evaluate the robustness of our approach under standard operating conditions,
        where the robot is tasked with autonomously loading three colored plates into a dishwasher.
      </p>
      <p>
        Behavior Cloning (BC) often fails due to its inability to capture the multimodal nature of the demonstrations,
        Diffusion Policy is capable of modeling the distribution but suffers from high latency
        In contrast, our Choice Policy successfully completes the task by efficiently modeling multiple candidate actions in a single forward pass, providing the precise, high-frequency control.
      </p>
      <div class="row mt-4">
        <div class="col-md-4">
          <h5 class="text-center mb-3">Choice Policy</h5>
          <div class="video-container">
            <video autoplay muted loop playsinline controls muted preload="metadata">
              <source data-src="./videos/eval/normal_cp.mp4">
            </video>
          </div>
        </div>

        <div class="col-md-4">
          <h5 class="text-center mb-3">Behavior Cloning Policy</h5>
          <div class="video-container">
            <video autoplay muted loop playsinline controls muted preload="metadata">
              <source data-src="./videos/eval/normal_bc.mp4">
            </video>
          </div>
        </div>

        <div class="col-md-4">
          <h5 class="text-center mb-3">Diffusion Policy</h5>
          <div class="video-container">
            <video autoplay muted loop playsinline controls muted preload="metadata">
              <source data-src="./videos/eval/normal_dp.mp4">
            </video>
          </div>
        </div>
      </div>
      <p class="text-muted" style="font-size: 0.85rem; font-style: italic; margin-top: 1rem;">
        *Note: To ensure a fair assessment of policy performance, trials interrupted by external hardware failures or network connection timeouts are excluded from the success rate statistics.
      </p>
    </div>

    <div class="row my-5">
      <h2>Citation</h2>
      <div class="col-md-12 mt-3">
        <pre>
          @article{qi2025coordinated,
             title={Coordinated Humanoid Manipulation with Choice Policies},
             author={Qi, Haozhi and Wang, Yen-Jen and Lin, Toru and Yi Brent and Ma, Yi and Sreenath, Koushil and Malik, Jitendra},
             journal={arXiv:2512.25072}
             year={2025}
          }
        </pre>
      </div>
    </div>

    <div class="my-4">
      <div class="abstract-section">
        <h4 class="mb-4">Acknowledgements</h4>
        <p>
          This work is supported in part by the program
          "Design of Robustly Implementable Autonomous and Intelligent Machines (TIAMAT)",
          Defense Advanced Research Projects Agency award number HR00112490425.
        </p>
      </div>
    </div>

    <div class="text-center mb-5">
      <hr/>
      <small style="color: #666;">
        Website inspired by
        <a href="https://www.liruilong.cn/prope/" target="_blank">
          PRoPE
        </a>
      </small>
    </div>

  </div>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      function makeSlider(videoIds, prevBtnId, nextBtnId, indicatorId, trackId) {
        const prevBtn = document.getElementById(prevBtnId);
        const nextBtn = document.getElementById(nextBtnId);
        const indicatorContainer = document.getElementById(indicatorId);
        const track = document.getElementById(trackId);

        let index = 0;
        const total = videoIds.length;

        const dots = videoIds.map((_, i) => {
          const dot = document.createElement('button');
          dot.type = 'button';
          dot.className = 'slider-dot' + (i === 0 ? ' active' : '');
          dot.addEventListener('click', function () {
            slideTo(i);
          });
          indicatorContainer.appendChild(dot);
          return dot;
        });

        function updateIndicators() {
          dots.forEach((d, i) => {
            d.classList.toggle('active', i === index);
          });
        }

        function slideTo(nextIndex) {
          index = nextIndex;
          track.style.transform = `translateX(-${index * 100}%)`;
          updateIndicators();
        }

        prevBtn.addEventListener('click', function (e) {
          e.preventDefault();
          const next = (index - 1 + total) % total;
          slideTo(next);
        });

        nextBtn.addEventListener('click', function (e) {
          e.preventDefault();
          const next = (index + 1) % total;
          slideTo(next);
        });
      }

      // TLDR slider
      makeSlider(
        ['tldr-video-0', 'tldr-video-1', 'tldr-video-2', 'tldr-video-3', 'tldr-video-4', 'tldr-video-5', 'tldr-video-6', 'tldr-video-7'],
        'tldr-prev',
        'tldr-next',
        'tldr-indicators',
        'tldr-track'
      );

      // Bolt-nut slider
      makeSlider(
        ['bn-video-0', 'bn-video-1', 'bn-video-2', 'bn-video-3'],
        'bn-prev',
        'bn-next',
        'bn-indicators',
        'bn-track'
      );

      // Screwdriver slider
      makeSlider(
        ['sc-video-0', 'sc-video-1'],
        'sc-prev',
        'sc-next',
        'sc-indicators',
        'sc-track'
      );
    });

    // Lazy loading for videos
    document.addEventListener("DOMContentLoaded", function() {
      const videoElements = document.querySelectorAll("video");
      const observer = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const videoElement = entry.target;
            const source = videoElement.querySelector('source[data-src]');
            if (source) {
              source.src = source.getAttribute("data-src");
              videoElement.load();
            }
            observer.unobserve(videoElement);
          }
        });
      }, { threshold: 0.1 });

      videoElements.forEach(video => {
        const source = video.querySelector('source[data-src]');
        if (source) {
          observer.observe(video);
        }
      });
    });
  </script>
</body>

</html>
